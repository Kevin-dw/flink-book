# flink内核分析

## 深入分析flink的网络栈

参考链接：https://flink.apache.org/2019/06/05/flink-network-stack.html

flink的网络栈是flink-runtime模块的核心组件之一，支撑了flink的每一个作业的运行。它将运行子任务的任务管理器连接在了一起。所以flink的网络栈对我们的吞吐量和低延迟有着至关重要的作用。flink里面的网络栈使用了两个著名的组件：Akka和Netty。

- 作业管理器和任务管理器之间的通信使用Akka组件。
- 任务管理器之间的通信使用更加底层的API：Netty库。

接下来，我们首先从更高层次的抽象来看一下操作符之间的通信，然后再详细研究一下flink的物理实现以及flink所做的各种优化。我们回简要的讲解一下flink做的优化以及flink在吞吐量和延迟之间所做的权衡。

### 逻辑视图

flink的网络栈提供了以下子任务之间通信的逻辑视图，例如`keyBy()`所需要的网络shuffle。

![](./image/flink-network-stack1.png)

这里我们抽象出三种概念：

* 子任务输出类型（ResultPartitionType）：
  * 流水线式发送数据 (有界或者无界数据流): 一旦数据产生，立即向下游发送数据。无论有界数据集还是无界数据集，都采用one-to-one的方式向下游发送。
  * 阻塞式发送数据: 只有当完整的计算结果产生时才向下游发送计算结果。
* 调度类型:
  * 一次全都部署的方式 (激进的调度方式): 将一个作业的所有子任务同时部署（针对流式应用）。
  * 当上游发送数据时部署当前子任务 (惰性的调度方式): 当算子的生产者（也就是上游算子）生产数据的时候才部署这个算子子任务。
  * 上游产生完整计算结果时部署当前子任务: 当算子的生产者完成它的所有计算，并发送完整的计算结果时，才部署当前子任务。
* 数据传输:
  * 高吞吐: flink将需要发送的数据缓存到网络缓存中，然后一起发送它们。而不是一条数据一条数据的发送。这将会降低均摊到每条数据的发送代价，也就提高了吞吐量。
  * 低延迟: 我们可以通过发送一个没有完全填满的网络缓冲区的数据，来降低发送数据的延时。当然，这样我们就为了低延迟而牺牲了吞吐量。

接下来，我们将看一下吞吐量和低延迟方面的网络栈优化。我们会详细了解以下输出和调度类型。首先，我们需要明白，子任务的输出类型和调度类型是紧密交织在一起的。

流水线式的数据传输的`ResultPartition`是一种流式风格的输出。所以我们需要一个运行起来的目标子任务来接收发送的数据。所以目标子任务必须在上游的计算结果或者第一条输出产生之前就调度部署跑起来。批处理作业处理的是有界数据`ResultPartition`而流处理作业处理的是无界数据`ResultPartition`。

批处理作业在生产计算结果时可能是以阻塞的方式生产的，这取决于操作符和使用的连接模式。在这种情况下，必须计算出完整的计算结果，然后接收计算结果的任务才会被部署。这允许批处理作业更加有效的工作，且消耗更少的计算资源。